{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kervolution Again\n",
    "\n",
    "Attempt to replicate results from: https://arxiv.org/abs/1904.03955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "## eh, dude?\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kresnet, trying to get it working\n",
    "\n",
    "layers stuff from: https://github.com/gan3sh500/kervolution-pytorch/blob/master/layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When bias is not none, this thing fails\n",
    "class LinearKernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearKernel, self).__init__()\n",
    "    \n",
    "    def forward(self, x_unf, w, b):\n",
    "        t = x_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2)\n",
    "        if b is not None:\n",
    "            return t + b\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearKernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearKernel, self).__init__()\n",
    "    \n",
    "    def forward(self, x_unf, w, b):\n",
    "        output = x_unf.matmul(w.t())\n",
    "        if bias is not None :\n",
    "            output += b\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Kervolution**\n",
    "\n",
    "K<sub>p</sub>(X,W) = (X<sup>T</sup> W + c<sub>p</sub>)<sup>d<sub>p</sub></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialKernel(LinearKernel):\n",
    "    def __init__(self, cp=2.0, dp=3, train_cp=True):\n",
    "        super(PolynomialKernel, self).__init__()\n",
    "        self.cp = nn.parameter.Parameter(torch.tensor(cp, requires_grad=train_cp))\n",
    "        self.dp = dp\n",
    "\n",
    "    def forward(self, x_unf, w, b):\n",
    "        return (self.cp + super(PolynomialKernel, self).forward(x_unf, w, b))**self.dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doesnt work\n",
    "class GaussianKernel(nn.Module):\n",
    "    def __init__(self, gamma=1.0):\n",
    "        super(GaussianKernel, self).__init__()\n",
    "        self.gamma = torch.nn.parameter.Parameter(\n",
    "                            torch.tensor(gamma, requires_grad=True))\n",
    "    \n",
    "    def forward(self, x_unf, w, b):\n",
    "        l = x_unf.transpose(1, 2)[:, :, :, None] - w.view(1, 1, -1, w.size(0))\n",
    "        l = l.sum(l**2, 2)\n",
    "        t = torch.exp(-self.gamma * l)\n",
    "        if b is not None:\n",
    "            return t + b\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, kernel_fn=PolynomialKernel,\n",
    "                 stride=1, padding=0, dilation=1, groups=1, bias=None,\n",
    "                 padding_mode='zeros'):\n",
    "        '''\n",
    "        Follows the same API as torch Conv2d except kernel_fn.\n",
    "        kernel_fn should be an instance of the above kernels.\n",
    "        '''\n",
    "        super(KernelConv2d, self).__init__(in_channels, out_channels, \n",
    "                                           kernel_size, stride, padding,\n",
    "                                           dilation, groups, bias, padding_mode)\n",
    "        self.kernel_fn = kernel_fn()\n",
    "   \n",
    "    def compute_shape(self, x):\n",
    "        h = (x.shape[2] + 2 * self.padding[0] - 1 * (self.kernel_size[0] - 1) - 1) // self.stride[0] + 1\n",
    "        w = (x.shape[3] + 2 * self.padding[1] - 1 * (self.kernel_size[1] - 1) - 1) // self.stride[1] + 1\n",
    "        return h, w\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print('x.shape:',x.shape)\n",
    "        x_unf = nn.functional.unfold(x, self.kernel_size, self.dilation,self.padding, self.stride)\n",
    "        #print('x_unf.shape:',x_unf.shape)\n",
    "        h, w = self.compute_shape(x)\n",
    "     \n",
    "        #print('h,w:',h,w)\n",
    "        #print('self.weight.shape:',self.weight.shape)\n",
    "        result = self.kernel_fn(x_unf, self.weight, self.bias).view(x.shape[0], -1, h, w)\n",
    "        #print('result.shape:',result.shape)\n",
    "        #print('***')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_conv = KernelConv2d(3,32,3,PolynomialKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture from: https://github.com/wang-chen/KervNets\n",
    "\n",
    "class BasicKervBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicKervBlock, self).__init__()\n",
    "        self.kerv1 = KernelConv2d(in_planes, planes, kernel_size=3,stride=stride,padding=1, bias=None)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.kerv2 = KernelConv2d(planes, planes, kernel_size=3,stride=1, padding=1, bias=None)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                KernelConv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=None),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.kerv1(x)))\n",
    "        out = self.bn2(self.kerv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(KResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.kerv1 = KernelConv2d(3, 64, 3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.kerv1(x)))\n",
    "        out = F.relu(self.layer1(out))\n",
    "        out = F.relu(self.layer2(out))\n",
    "        out = F.relu(self.layer3(out))\n",
    "        out = F.relu(self.layer4(out))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "def KResNet18(num_classes=10):\n",
    "    return KResNet(BasicKervBlock, [2,2,2,2], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "## Test network\n",
    "\n",
    "net = KResNet18()\n",
    "y = net(Variable(torch.randn(8,3,32,32)))\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "2. Define a Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and normalizing CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=num_workers)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ship plane truck  frog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = KResNet18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9,weight_decay=1e-4)\n",
    "\n",
    "# from Kervolutional Neural Networks article (5.2):\n",
    "#\n",
    "# The learning rate is set to 0.1, and is reduced every 30 epochs. Also, a weight decay of 10 −4\n",
    "# and a momentum of 0.9 without dampening are employed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the network (GPU, because very slow on CPU)\n",
    "\n",
    "We have to loop over our data iterator, and feed the inputs to the network and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KResNet(\n",
       "  (kerv1): KernelConv2d(\n",
       "    3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "    (kernel_fn): PolynomialKernel()\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): KernelConv2d(\n",
       "          64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (kernel_fn): PolynomialKernel()\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): KernelConv2d(\n",
       "          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (kernel_fn): PolynomialKernel()\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): KernelConv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (kernel_fn): PolynomialKernel()\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicKervBlock(\n",
       "      (kerv1): KernelConv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (kerv2): KernelConv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (kernel_fn): PolynomialKernel()\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.336\n",
      "[2,   100] loss: 2.308\n",
      "[3,   100] loss: 2.306\n",
      "[4,   100] loss: 2.302\n",
      "[5,   100] loss: 2.301\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # send the inputs and targets at every step to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network doesnt seem able to learn**\n",
    "\n",
    "loss hangs around 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
